{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3879fa",
   "metadata": {},
   "source": [
    "# Spark Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693fba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "from env import user, pwd, host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08499f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_url(db):\n",
    "    '''input df and output sql connection string'''\n",
    "    return (f'mysql+pymysql://{user}:{pwd}@{host}/{db}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66c455",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755438f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/19 14:53:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://richards-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1174a7e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create enviroment\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2fc66",
   "metadata": {},
   "source": [
    "### load mpg data set from pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551e9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e58c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[manufacturer: string, model: string, displ: double, year: bigint, cyl: bigint, trans: string, drv: string, cty: bigint, hwy: bigint, fl: string, class: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c87000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b59db6",
   "metadata": {},
   "source": [
    "### write datafame to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30572adc",
   "metadata": {},
   "source": [
    "- `json`: for writing to a local json file(s)\n",
    "- `csv`: for writing to a local csv file(s)\n",
    "- `parquet`: Parquet is a very popular columnar storage format for Hadoop.\n",
    "- `jdbc`: for writing to a SQL database table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8bbb4",
   "metadata": {},
   "source": [
    "#### write file to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d07a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#df.write.type\n",
    "mpg.write.json('data/mpg_json',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ea04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3012f768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00005-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00006-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00000-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00005-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00002-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '._SUCCESS.crc',\n",
       " '.part-00002-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00007-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00001-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00006-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00007-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00003-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00004-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " '_SUCCESS',\n",
       " 'part-00001-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00003-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc',\n",
       " 'part-00004-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json',\n",
       " '.part-00000-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json.crc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/mpg_json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a839530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = [fn for fn in os.listdir('data/mpg_json/') if not fn.startswith('.')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c583563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'part-00005-61804ae3-1ce4-4925-b047-5a9521172f6e-c000.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e452127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.json(f'data/mpg_json/{first_file}').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caff6b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.json(f'data/mpg_json/').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14cb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf08c75f",
   "metadata": {},
   "source": [
    "#### write dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21463422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.write.format()\n",
    "(\n",
    "mpg.write.format('csv')\n",
    "    .mode('overwrite')\n",
    "    .option('header',True)\n",
    "    .save('data/mpg_csv')\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b6a58",
   "metadata": {},
   "source": [
    "### read files\n",
    "- spark.read.[type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057159b",
   "metadata": {},
   "source": [
    "#### read json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380e06a",
   "metadata": {},
   "source": [
    "#### read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36ea678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep written csv headers\n",
    "(\n",
    "    spark.read.format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load(\"data/mpg_csv\")\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e36e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[manufacturer: string, model: string, displ: string, year: string, cyl: string, trans: string, drv: string, cty: string, hwy: string, fl: string, class: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep written csv headers\n",
    "(\n",
    "    spark.read.format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load(\"data/mpg_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69b4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c839b2a6",
   "metadata": {},
   "source": [
    "### load source from 311_data in sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3abd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sql query\n",
    "# url = get_db_url('311_data')\n",
    "# query = 'select source_id, source_username from source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017046b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make pandas df\n",
    "# pandas_df = pd.read_sql(query, url)\n",
    "# pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d66358",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_csv('311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17858a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5769739f",
   "metadata": {},
   "source": [
    "### load cases from 311_data from sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54618aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sql query\n",
    "# query = 'select * from cases limit 100000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ee891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas df\n",
    "# pandas_df = pd.read_sql(query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb9b4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[case_id: bigint, case_opened_date: string, case_closed_date: string, SLA_due_date: string, case_late: string, num_days_late: double, case_closed: string, dept_division: string, service_request_type: string, SLA_days: double, case_status: string, source_id: string, request_address: string, council_district: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark df\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47c4e583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------\n",
      " case_id              | 1014127332                            \n",
      " case_opened_date     | 1/1/18 0:42                           \n",
      " case_closed_date     | 1/1/18 12:29                          \n",
      " SLA_due_date         | 9/26/20 0:42                          \n",
      " case_late            | NO                                    \n",
      " num_days_late        | -998.5087616                          \n",
      " case_closed          | YES                                   \n",
      " dept_division        | Field Operations                      \n",
      " service_request_type | Stray Animal                          \n",
      " SLA_days             | 999.0                                 \n",
      " case_status          | Closed                                \n",
      " source_id            | svcCRMLS                              \n",
      " request_address      | 2315  EL PASO ST, San Antonio, 78207  \n",
      " council_district     | 5                                     \n",
      "-RECORD 1-----------------------------------------------------\n",
      " case_id              | 1014127333                            \n",
      " case_opened_date     | 1/1/18 0:46                           \n",
      " case_closed_date     | 1/3/18 8:11                           \n",
      " SLA_due_date         | 1/5/18 8:30                           \n",
      " case_late            | NO                                    \n",
      " num_days_late        | -2.012604167                          \n",
      " case_closed          | YES                                   \n",
      " dept_division        | Storm Water                           \n",
      " service_request_type | Removal Of Obstruction                \n",
      " SLA_days             | 4.322222222                           \n",
      " case_status          | Closed                                \n",
      " source_id            | svcCRMSS                              \n",
      " request_address      | 2215  GOLIAD RD, San Antonio, 78223   \n",
      " council_district     | 3                                     \n",
      "-RECORD 2-----------------------------------------------------\n",
      " case_id              | 1014127334                            \n",
      " case_opened_date     | 1/1/18 0:48                           \n",
      " case_closed_date     | 1/2/18 7:57                           \n",
      " SLA_due_date         | 1/5/18 8:30                           \n",
      " case_late            | NO                                    \n",
      " num_days_late        | -3.022337963                          \n",
      " case_closed          | YES                                   \n",
      " dept_division        | Storm Water                           \n",
      " service_request_type | Removal Of Obstruction                \n",
      " SLA_days             | 4.320729167                           \n",
      " case_status          | Closed                                \n",
      " source_id            | svcCRMSS                              \n",
      " request_address      | 102  PALFREY ST W, San Antonio, 78223 \n",
      " council_district     | 3                                     \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/19 14:54:09 WARN TaskSetManager: Stage 16 contains a task of very large size (1346 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "df.show(3, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df26f2f",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3f40e",
   "metadata": {},
   "source": [
    "- rename columns\n",
    "- correct datatypes\n",
    "- data transformation\n",
    "- make new features\n",
    "- join tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aec4fe",
   "metadata": {},
   "source": [
    "### rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5929b1",
   "metadata": {},
   "source": [
    "#### change SLA_due_date to case_due_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('SLA_due_date','case_due_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98297cf",
   "metadata": {},
   "source": [
    "### correct datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('case_closed','case_late').show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50584b86",
   "metadata": {},
   "source": [
    "#### change close_closed and case_late columns into boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use condition to make true and false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65df82",
   "metadata": {},
   "source": [
    "#### change council_district datatype to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use .cast()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d21ecb",
   "metadata": {},
   "source": [
    "#### change dates to datetype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d94432",
   "metadata": {},
   "source": [
    "format date strings: https://docs.oracle.com/javase/10/docs/api/java/time/format/DateTimeFormatter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b4f96-3f18-46a9-9598-f8c6e8ba3e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cbca0fd",
   "metadata": {},
   "source": [
    "### data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd01a0",
   "metadata": {},
   "source": [
    "#### normalize address\n",
    "- `lower`: lowercase everything\n",
    "- `trim`: remove whitespace on the edges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bd761",
   "metadata": {},
   "source": [
    "#### change num_days_late to num_weeks_late"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bc28f",
   "metadata": {},
   "source": [
    "#### change council_district to int and pad with 00s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecc429",
   "metadata": {},
   "source": [
    "### new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059b9f5",
   "metadata": {},
   "source": [
    "#### create zip code column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b302f",
   "metadata": {},
   "source": [
    "#### create case_lifetime column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d43cc6",
   "metadata": {},
   "source": [
    "- case_age: how long since the case first opened\n",
    "- days_to_close: the number of days between days opened and days closed\n",
    "- case_lifetime: if the case is open, how long since the case opened, if the case is closed, the number of days to close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use datediff() to find the difference between two dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732677de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create case_lifetime column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bde5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaeef4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22524bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb016e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638518f0",
   "metadata": {},
   "source": [
    "### join the dept table from sql to our current df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('dept_division').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b24e71-2825-464b-b54a-a3c03499904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dept table from sql\n",
    "query = 'select * from dept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a11688-7ce9-483d-8493-db724a883c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_db_url('311_data')\n",
    "dept = pd.read_sql(query, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa1ab1-4bda-4274-ad06-f7d5a755a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept = spark.createDataFrame(dept)\n",
    "dept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904326a",
   "metadata": {},
   "source": [
    "### train, validate, test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f04c04",
   "metadata": {},
   "source": [
    "- `.randomSplit` to split df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f08570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
